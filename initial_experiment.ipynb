{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stanfordcorenlp\n",
      "  Downloading stanfordcorenlp-3.9.1.1-py2.py3-none-any.whl (5.7 kB)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/lib/python3.9/site-packages (from stanfordcorenlp) (5.8.0)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.9/site-packages (from stanfordcorenlp) (2.26.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.9/site-packages (from requests->stanfordcorenlp) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/lib/python3.9/site-packages (from requests->stanfordcorenlp) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.9/site-packages (from requests->stanfordcorenlp) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from requests->stanfordcorenlp) (2.0.4)\n",
      "Installing collected packages: stanfordcorenlp\n",
      "Successfully installed stanfordcorenlp-3.9.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install stanfordcorenlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/pp/qtk1lyns6zg8x9dlj6f5xvtm0000gn/T/ipykernel_63814/1391988386.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     44\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     45\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0m__name__\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m'__main__'\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 46\u001B[0;31m     \u001B[0msNLP\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mStanfordNLP\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     47\u001B[0m     \u001B[0mtext\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'A blog post using Stanford CoreNLP Server. Visit www.khalidalnajjar.com for more details.'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     48\u001B[0m     \u001B[0mprint\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;34m\"Annotate:\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msNLP\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mannotate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/pp/qtk1lyns6zg8x9dlj6f5xvtm0000gn/T/ipykernel_63814/1391988386.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, host, port)\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;32mclass\u001B[0m \u001B[0mStanfordNLP\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhost\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'http://localhost'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mport\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m9000\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m         self.nlp = StanfordCoreNLP(host, port=port,\n\u001B[0m\u001B[1;32m      8\u001B[0m                                    timeout=30000)  # , quiet=False, logging_level=logging.DEBUG)\n\u001B[1;32m      9\u001B[0m         self.props = {\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/stanfordcorenlp/corenlp.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, path_or_host, port, memory, lang, timeout, quiet, logging_level)\u001B[0m\n\u001B[1;32m    115\u001B[0m         \u001B[0;32mwhile\u001B[0m \u001B[0msock\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconnect_ex\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhost_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mport\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    116\u001B[0m             \u001B[0mlogging\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minfo\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Waiting until the server is available.'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 117\u001B[0;31m             \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    118\u001B[0m         \u001B[0mlogging\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minfo\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'The server is available.'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    119\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "import logging\n",
    "import json\n",
    "\n",
    "class StanfordNLP:\n",
    "    def __init__(self, host='http://localhost', port=9000):\n",
    "        self.nlp = StanfordCoreNLP(host, port=port,\n",
    "                                   timeout=30000)  # , quiet=False, logging_level=logging.DEBUG)\n",
    "        self.props = {\n",
    "            'annotators': 'tokenize,ssplit,pos,lemma,ner,parse,depparse,dcoref,relation',\n",
    "            'pipelineLanguage': 'en',\n",
    "            'outputFormat': 'json'\n",
    "        }\n",
    "\n",
    "    def word_tokenize(self, sentence):\n",
    "        return self.nlp.word_tokenize(sentence)\n",
    "\n",
    "    def pos(self, sentence):\n",
    "        return self.nlp.pos_tag(sentence)\n",
    "\n",
    "    def ner(self, sentence):\n",
    "        return self.nlp.ner(sentence)\n",
    "\n",
    "    def parse(self, sentence):\n",
    "        return self.nlp.parse(sentence)\n",
    "\n",
    "    def dependency_parse(self, sentence):\n",
    "        return self.nlp.dependency_parse(sentence)\n",
    "\n",
    "    def annotate(self, sentence):\n",
    "        return json.loads(self.nlp.annotate(sentence, properties=self.props))\n",
    "\n",
    "    @staticmethod\n",
    "    def tokens_to_dict(_tokens):\n",
    "        tokens = defaultdict(dict)\n",
    "        for token in _tokens:\n",
    "            tokens[int(token['index'])] = {\n",
    "                'word': token['word'],\n",
    "                'lemma': token['lemma'],\n",
    "                'pos': token['pos'],\n",
    "                'ner': token['ner']\n",
    "            }\n",
    "        return tokens\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    sNLP = StanfordNLP()\n",
    "    text = 'A blog post using Stanford CoreNLP Server. Visit www.khalidalnajjar.com for more details.'\n",
    "    print (\"Annotate:\", sNLP.annotate(text))\n",
    "    print (\"POS:\", sNLP.pos(text))\n",
    "    print (\"Tokens:\", sNLP.word_tokenize(text))\n",
    "    print (\"NER:\", sNLP.ner(text))\n",
    "    print (\"Parse:\", sNLP.parse(text))\n",
    "    print (\"Dep Parse:\", sNLP.dependency_parse(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\r\n",
      "  Using cached gensim-4.1.2-cp39-cp39-macosx_10_9_x86_64.whl (24.0 MB)\r\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/anaconda3/lib/python3.9/site-packages (from gensim) (1.7.1)\r\n",
      "Collecting smart-open>=1.8.1\r\n",
      "  Using cached smart_open-5.2.1-py3-none-any.whl (58 kB)\r\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/anaconda3/lib/python3.9/site-packages (from gensim) (1.20.3)\r\n",
      "Installing collected packages: smart-open, gensim\r\n",
      "Successfully installed gensim-4.1.2 smart-open-5.2.1\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}